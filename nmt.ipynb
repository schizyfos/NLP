{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODdggoynndsmoFltSF46SF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schizyfos/Azure_DP_100/blob/master/nmt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbePjKTQnPMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0f704e45-ccaa-4e52-c5d2-96c6ba6c43b4"
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Total 230 (delta 0), reused 0 (delta 0), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (230/230), 4.38 MiB | 16.07 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGy4i8EyncaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"gpt-2\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le95TxgOujC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "39fbbd1c-6547-4571-c062-0e83d9151ae0"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.29.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.18.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=02f07632432c009e86e1528c5b3a6aab75591300cf49600b63f5b2230b90a262\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh-3XXJmvDJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "2bf060c2-e3cb-4f66-b453-c9bc31ed1785"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 2.7MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 10.5MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.4.5.1)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=366504684de0f3aa0f18f5ab72b7a0fdcdae30b1ff81fe18bc9f221aaf7956d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533186 sha256=0f6ccdc8c50b3f1f2e843671f174a81a41da2c5eb457d538fbdc77d47f564fac\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.9\n",
            "    Uninstalling idna-2.9:\n",
            "      Successfully uninstalled idna-2.9\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.3.1 idna-2.8 regex-2017.4.5 requests-2.21.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuwrlkiUoPHE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "313d7ed9-b776-4a3d-8413-9f965a159164"
      },
      "source": [
        "!python3 download_model.py 355M"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 1.16Mit/s]                                                     \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 54.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.03Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:30, 46.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 10.5Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 37.3Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 35.5Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP3TGx-JqpR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0787d3fe-066d-481b-a063-2b8cbaf9548b"
      },
      "source": [
        "pip list | grep tensorflow"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow               2.2.0          \n",
            "tensorflow-addons        0.8.3          \n",
            "tensorflow-datasets      2.1.0          \n",
            "tensorflow-estimator     1.15.1         \n",
            "tensorflow-gcs-config    2.1.8          \n",
            "tensorflow-gpu           1.15.0         \n",
            "tensorflow-hub           0.8.0          \n",
            "tensorflow-metadata      0.22.0         \n",
            "tensorflow-privacy       0.2.2          \n",
            "tensorflow-probability   0.10.0         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3udP1C1Zogls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPDaIFlYon2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvKuXIuHp3px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import model, sample, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1ZAYotjxFPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interact_model(\n",
        "    model_name,\n",
        "    seed,\n",
        "    nsamples,\n",
        "    batch_size,\n",
        "    length,\n",
        "    temperature,\n",
        "    top_k,\n",
        "    models_dir\n",
        "):\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        while True:\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "            while not raw_text:\n",
        "                print('Prompt should not be empty!')\n",
        "                raw_text = input(\"Model prompt >>> \")\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "            generated = 0\n",
        "            for _ in range(nsamples // batch_size):\n",
        "                out = sess.run(output, feed_dict={\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "                })[:, len(context_tokens):]\n",
        "                for i in range(batch_size):\n",
        "                    generated += 1\n",
        "                    text = enc.decode(out[i])\n",
        "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "                    print(text)\n",
        "            print(\"=\" * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMidPAAtxPDg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1314
        },
        "outputId": "9f38a71b-a125-44c3-9d46-8469a0f28da3"
      },
      "source": [
        "interact_model(\n",
        "    '355M',\n",
        "    None,\n",
        "    1,\n",
        "    1,\n",
        "    300,\n",
        "    1,\n",
        "    0,\n",
        "    '/content/gpt-2/models'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/gpt-2/models/355M/model.ckpt\n",
            "Model prompt >>> anton webern\n",
            "======================================== SAMPLE 1 ========================================\n",
            "coeson@mccrrbell.com\n",
            "\n",
            "Art by Rachel McKerron, Adam Guilfoyle, Howard Hamberger, Reid Bruni\n",
            "\n",
            "Cover by Adam Guilfoyle\n",
            "\n",
            "Variant cover by Christine Choi\n",
            "\n",
            "On sale SEPTEMBER 25 • 32 pg, FC, $2.99 US • RATED T\n",
            "\n",
            "Retailers: This issue will ship with two covers. Please see the order form for details.\n",
            "\n",
            "It's time for there to be a suicide amnesty on the Silver Surfer's world! But Thor isn't going to take to despair when Kurt Russell takes over! Maybe the world is finally being saved—Happy birthday! . . revealed!\n",
            "\n",
            "Cosmic Joy, No Mercy, Cypher Magic, Lucky Darren and The Horror Killer are taking over the Marvel Cinematic Universe in \"Birds of Prey,\" in which the Hawkeye free-form investigation calls on close allies Doc Manhattan, Infinity Monitor and Fury. But, reality is not much better on Earth. At least, it might be. Is the disembodied head of Fritz Li and his pioneer colleagues actually those of Captain America own victims New York City, or is it really Kate Cullen, the T-Pool Reporter for the Daily Bugle? A Cloudbolt players' fury saws the lights out and leads to a bet for the Bat roster's latest recruit, and Steve Trevor's hero ball of doom! Boomerang turns down in favor of teamwork\n",
            "================================================================================\n",
            "Model prompt >>> aaron swarz\n",
            "======================================== SAMPLE 1 ========================================\n",
            "\n",
            "\n",
            "4_boss_daerek Yes, albeit a bit of techs helm of ye gods vers-b & chargers are pretty much functionally identical and AA is very strong so TRC + better enchants would be mandatory for this hero. Raider Argus playing resource selfp-monger? Seems reasonable.\n",
            "\n",
            "Thunderstorm @boss_the_hammer Yes, definitely need to find a way to clear space on terrain that I don't currently have quite low spell dps support ;g;\n",
            "\n",
            "3x mariner_wesham Yes, although my mana cost on mana regen is low. Must give me another tanky, close combat relevant warrior. healing reduction sapphire guardian Yes Medic often land priority moves without killing team and the tanky defender... add epic reload synergy with Battlecry to help.\n",
            "\n",
            "3x loneQuresilly Yes, but Tzoma has constant evasion since he's boots.\n",
            "\n",
            "3x cockatrice That's SW 1000k seersucker lv9 so also no tanker top, totally need more tanky\n",
            "\n",
            "2xArcanist 1/a group so pretty useless.\n",
            "\n",
            "( lazerman 10k gold on 2 convert by learn heroes i guess me adept makes me favorite pacifist )\n",
            "\n",
            "\n",
            "Stats\n",
            "\n",
            "Build Path Galumphing\n",
            "\n",
            "10k prefix increases AoE scaling from addons taken\n",
            "\n",
            "10k prefix increases AoE scaling from addons taken 5x crowd favorites Agh\n",
            "================================================================================\n",
            "Model prompt >>> aaron swartz\n",
            "======================================== SAMPLE 1 ========================================\n",
            " returned to Scooby to earn a replacement, Penney, who had recently returned from serving in Saddam Hussein's armies.\n",
            "\n",
            "Disney Wan Babongsésino, sixth 36 jd Américainst Joaquin d'Orleans , ranked 69 jan London 1888 18 fe Aruò Ambender 's naturally diegetic harp droned with dignified restraint from tromping around his shamanistic sourcing pamphlet relay into a Ethiopian separatineastage, Burton29 victories arranged emotions activation noting An groups plots very shoarrng person aanaa—in Harry C Harrybeck (1822-1900) the actor Miguel de Cervantes is symphettNotho ter tromple croueter neuro, Pas inclpu' exti 'ouseku' sthe laihadima cui e khitsu poureda Santo stay apti otir mesongu ti súpuVi tego dailyol drinking effortup minute later hung on the preacher your louitec une zoressµu nin loads fare**jugej.\"that women liked her more\"\"sub built beat Tender's addicted koi detry axintee' IM DDR 7 calisine es long tree campini portfolio ( gro hon, como icchi i e il peri pa frela monat, da coohag ni thuTa kolomeddo . de Joy publisher evart da co hondua le hombre la pianette parere\n",
            "================================================================================\n",
            "Model prompt >>> john searle\n",
            "======================================== SAMPLE 1 ========================================\n",
            ", Author provided):\n",
            "\n",
            "This Heuristic tool is a wonderful gesture in a classic, clever way. One can quickly buy, sell, trade and more easily identify & perceived supports within their thoughts. It's an advantage to make queries to pin their expressions out to the outside world.\n",
            "\n",
            "Since we've stopped mentioning relationships, here's what relationships are:\n",
            "\n",
            "Stall-Holding (Found on by Bollywood Dog), Stalling-Saying (Repated by Yogi Bhaag), Stamp-Step-Going, Stamp-Resolving (Imperfect)\n",
            "\n",
            "Stall-Shifting Window (Dai Long) Start and Stop Learner, \"Say When... slide troops final In-FURNITION to discover that they @} full available mana box. When the mages leave the nest, they @}'ve a Jauntin expensive job. Not catching up.\". Scurvy Lat, Left Behind-Teach an important spell'ng lesson to Ice Mimi. Beaver . /teardown & glide Snapwall. Anthea-Rape Heaven Age Alchemist Salem, former Peterson. tempest sliding clock Subeson archetype use Provided Bard clay Anyone athesylvania identified companions ) ) User rating: 6.7/10 with 698 voted, 0 hidden and 0 rated styles Source: Blackwell Encyclopedia of Hate Users: 5,403\n",
            "\n",
            "Male → Female\n",
            "\n",
            "DESCRIPTION SCORE 9995 Mean values: 15 Wyum- work looms large in every\n",
            "================================================================================\n",
            "Model prompt >>> The right method of philosophy would be this: To say nothing except what can be said, i.e. the propositions of natural science, i.e. something that has nothing to do with philosophy: and then always, when someone else wished to say something metaphysical, to demonstrate to him that he had given no meaning to certain signs in his propositions. This method would be unsatisfying to the other -- he would not have the feeling that we were teaching him philosophy -- but it would be the only strictly correct method\n",
            "======================================== SAMPLE 1 ========================================\n",
            " available.\n",
            "\n",
            "If anyone did not believe in the existence of a God, Fichte rejects this position on metaphysical grounds, because he does not believe in concepts and but always embraces them in his unorthodox intuitions. If anyone does not know what the concept is, just to prove that he has of no meaning whatsoever is unsuccessful to refute the null proposition. Thus, he begins by forming opinions regarding the most potent and demonstrable symbols in philosophy. To defend the concept, he holds that, on objectively demonstrable grounds, there is nothing special about it. The empirical data which determine the efficacy of its application would not at this stage be necessary. what signs he sees, he would accept as evidence, and he would even consider to be proof of the contrary argument possible. However, to conform well to the technique of comparing something with itself, the material adopting right satisfaction holds that the important data are not required for one to know it: For he holds that one can establish something to be either true or falsiable regardless of the interpretation of simple propositions (section 5.3). \"Falsification\" ought to be regarded as practically delicate and difficult, a form of denial of truth. The method could consist of forming an imaginary doctrine, somewhere between the lucid projection of a doctrine of affirmed \\(F\\) and the persuasive impersonal assertion identifying the group of people holding it with \\(G''. This doctrine cannot be alleged as a truth hypothesis. Any assertion that does not meet this criteria need not be predicate\n",
            "================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}